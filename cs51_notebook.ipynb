{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 51 Final Project Interface\n",
    "\n",
    "By: Olivia Angiuli, Martin Reindl, Ty Rocca, Wilder Wohns\n",
    "\n",
    "**Purpose:** This top level iPython notebook is designed to be a place to see how our code works. It is also a good way for us to show off our results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, struct,random #,\n",
    "# import sys\n",
    "from numpy import append, array, int8, uint8, zeros\n",
    "import Initialize\n",
    "import Accuracy\n",
    "import Distance\n",
    "import Load\n",
    "import Kmeans\n",
    "import ClassifyClusters\n",
    "import base64\n",
    "import json\n",
    "import timeit\n",
    "\n",
    "######################################\n",
    "# Load in training images and labels #\n",
    "######################################\n",
    "\n",
    "# load training and testing images and labels as 60,000 x 28 x 28 array\n",
    "train_images,train_labels = Load.load_mnist(\"training\",path=os.getcwd(), prop = 5)\n",
    "test_images,test_labels = Load.load_mnist(\"testing\",path=os.getcwd())\n",
    "\n",
    "# flatten training images into 60,000 x 784 array\n",
    "train_images_flat = np.array([np.ravel(img) for img in train_images])\n",
    "test_images_flat = np.array([np.ravel(img) for img in test_images])\n",
    "\n",
    "def main (k, m=\"means\", init_type=\"random\"):\n",
    "    \n",
    "    # Starting clustering timer\n",
    "    start_cluster = timeit.default_timer()\n",
    "    \n",
    "    # Process arguments\n",
    "    if k < 10:\n",
    "        raise ValueError(\"Minimum cluster number is 10\")\n",
    "    \n",
    "    #Process method of clustering\n",
    "    if m not in [\"means\", \"medoids\", \"medians\"]:\n",
    "        raise ValueError(\"Not a valid method specification; must be 'means',\\\n",
    "          'medoids', or 'medians'\")\n",
    "    \n",
    "    # Method for clustering\n",
    "    initial_clusters = None\n",
    "    if init_type == \"random\":\n",
    "        initial_clusters = Initialize.random_centers(k)\n",
    "    else:\n",
    "        init_type = \"kplusplus\"\n",
    "        initial_clusters = Initialize.kmeans_plusplus(k, train_images_flat,\n",
    "                                           dist_fn=Distance.sumsq)\n",
    "        \n",
    "        \n",
    "        \n",
    "    # Run clustering algorithm\n",
    "    final_responsibilities, final_clusters = Kmeans.kmeans(k, train_images_flat,\n",
    "        initial_clusters, distfn = Distance.sumsq, method=m)\n",
    "    \n",
    "    # Output of results\n",
    "    print final_responsibilities.sum(axis=0)\n",
    "\n",
    "    # Time to cluster\n",
    "    end_cluster = timeit.default_timer()\n",
    "    clustering_time = end_cluster - start_cluster\n",
    "    print \"Time spent clustering : \", clustering_time\n",
    "\n",
    "\n",
    "    # Save representative images to file.\n",
    "    title = m + \"_\" + init_type + \"_cluster\" + str(k)\n",
    "    Load.save_images(k, train_images, final_responsibilities, \n",
    "                     final_clusters, title)\n",
    "\n",
    "    # Calculate final accuracy for clusters\n",
    "    final, cluster_set = Accuracy.final_accuracy(final_responsibilities, \n",
    "        train_labels, train_images_flat, final_clusters)\n",
    "\n",
    "    # Now see how well we can classify the dataset\n",
    "    start_cluster_test = timeit.default_timer()\n",
    "    predictions = ClassifyClusters.classify(cluster_set, test_images_flat, \n",
    "        test_labels, distfn = Distance.sumsq, n=None)\n",
    "    finish_cluster_test = timeit.default_timer()\n",
    "\n",
    "    testing_time = finish_cluster_test - start_cluster_test\n",
    "    print \"Time spent testing : \", testing_time\n",
    "    \n",
    "    ###########\n",
    "    # Outputs #\n",
    "    ###########\n",
    "\n",
    "    # Serializing numpy array - from below source \n",
    "    # http://stackoverflow.com/questions/3488934/simplejson-and-numpy-array\n",
    "    class NumpyEncoder(json.JSONEncoder):\n",
    "        def default(self, obj):\n",
    "            \"\"\"\n",
    "            if input object is a ndarray it will be converted into a \n",
    "            dict holding dtype, shape and the data base64 encoded\n",
    "            \"\"\"\n",
    "            if isinstance(obj, np.ndarray):\n",
    "                data_b64 = base64.b64encode(obj.data)\n",
    "                return dict(__ndarray__=data_b64,\n",
    "                            dtype=str(obj.dtype),\n",
    "                            shape=obj.shape)\n",
    "            # Let the base class default method raise the TypeError\n",
    "            return json.JSONEncoder(self, obj)\n",
    "\n",
    "\n",
    "    def json_numpy_obj_hook(dct):\n",
    "        \"\"\"\n",
    "        Decodes a previously encoded numpy ndarray\n",
    "        with proper shape and dtype\n",
    "        :param dct: (dict) json encoded ndarray\n",
    "        :return: (ndarray) if input was an encoded ndarray\n",
    "        \"\"\"\n",
    "        if isinstance(dct, dict) and '__ndarray__' in dct:\n",
    "            data = base64.b64decode(dct['__ndarray__'])\n",
    "            return np.frombuffer(data, dct['dtype']).reshape(dct['shape'])\n",
    "        return dct\n",
    "\n",
    "\n",
    "    # k, prediction level, cluster_set, \n",
    "    results = {\"k\" : k, \"prediction_accuracy\" : predictions[1], \n",
    "    \"cluster_means\" : cluster_set, \"cluster_stats\" : final,\n",
    "    \"clustering_time\" : clustering_time, \"testing_time\" : testing_time}\n",
    "\n",
    "\n",
    "    with open('./' + title + '/' + title + '_results.json', 'w') as outfile:\n",
    "        json.dump(results, outfile, cls=NumpyEncoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [ 478.  228.  223.   93.  469.  432.  281.  297.  307.  192.]\n",
      "1 [ 347.  252.  245.  113.  479.  402.  352.  307.  315.  188.]\n",
      "2 [ 289.  270.  240.  121.  470.  410.  369.  292.  331.  208.]\n",
      "3 [ 264.  292.  240.  119.  452.  409.  365.  292.  334.  233.]\n",
      "4 [ 243.  310.  227.  121.  455.  407.  355.  283.  341.  258.]\n",
      "5 [ 233.  317.  225.  113.  467.  410.  341.  280.  346.  268.]\n",
      "6 [ 224.  325.  220.  108.  483.  409.  330.  272.  353.  276.]\n",
      "7 [ 223.  338.  215.  103.  495.  410.  318.  260.  356.  282.]\n",
      "8 [ 222.  351.  227.  103.  493.  406.  307.  257.  350.  284.]\n",
      "9 [ 223.  367.  227.  105.  496.  404.  291.  256.  342.  289.]\n",
      "10 [ 220.  395.  228.  105.  503.  398.  274.  254.  336.  287.]\n",
      "11 [ 219.  408.  229.  107.  503.  395.  260.  255.  334.  290.]\n",
      "12 [ 219.  407.  228.  108.  508.  391.  266.  249.  336.  288.]\n",
      "13 [ 218.  401.  228.  109.  515.  392.  264.  254.  330.  289.]\n",
      "14 [ 217.  399.  228.  110.  523.  395.  249.  257.  327.  295.]\n",
      "15 [ 217.  404.  228.  111.  523.  398.  236.  261.  325.  297.]\n",
      "16 [ 217.  403.  230.  111.  525.  397.  230.  266.  323.  298.]\n",
      "17 [ 217.  401.  230.  112.  526.  398.  230.  264.  322.  300.]\n",
      "18 [ 217.  401.  230.  111.  527.  397.  230.  264.  322.  301.]\n",
      "19 [ 217.  400.  229.  111.  527.  398.  230.  264.  322.  302.]\n",
      "20 [ 217.  399.  229.  111.  526.  398.  233.  263.  322.  302.]\n",
      "21 [ 217.  398.  229.  111.  526.  397.  233.  264.  322.  303.]\n",
      "22 [ 217.  400.  230.  111.  527.  396.  231.  263.  321.  304.]\n",
      "23 [ 217.  403.  230.  111.  526.  395.  230.  262.  322.  304.]\n",
      "24 [ 217.  404.  230.  111.  527.  395.  230.  260.  322.  304.]\n",
      "25 [ 217.  405.  230.  111.  527.  395.  230.  259.  322.  304.]\n",
      "[ 217.  405.  230.  111.  527.  395.  230.  259.  322.  304.]\n",
      "Time spent clustering :  30.5768530369\n",
      "Digit: 0  Purity: 93.5% SD: 1948.9  Count: 230\n",
      "Digit: 1  Purity: 53.6% SD: 1468.4  Count: 612\n",
      "Digit: 2  Purity: 49.7% SD: 1972.9  Count: 433\n",
      "Digit: 3  Purity: 42.3% SD: 1938.9  Count: 527\n",
      "Digit: 4  Purity: 62.5% SD: 1847.0  Count: 405\n",
      "Digit: 5  Purity:  0.0% SD:    0.0  Count: 0\n",
      "Digit: 6  Purity: 78.3% SD: 1799.4  Count: 304\n",
      "Digit: 7  Purity: 55.2% SD: 1653.4  Count: 489\n",
      "Digit: 8  Purity:  0.0% SD:    0.0  Count: 0\n",
      "Digit: 9  Purity:  0.0% SD:    0.0  Count: 0\n",
      "Our accuracy in predicting test data for k = 10 was 57.2357235724 %\n",
      "Time spent testing :  10.613754034\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# Call to function #\n",
    "####################\n",
    "main(10, m=\"medians\", init_type=\"k_plus_plus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# How to load the data back in \n",
    "# json.loads(dumped, object_hook=json_numpy_obj_hook)\n",
    "\n",
    "# source : http://stackoverflow.com/questions/3488934/simplejson-and-numpy-array/24375113#24375113\n",
    "import base64\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def json_numpy_obj_hook(dct):\n",
    "        \"\"\"\n",
    "        Decodes a previously encoded numpy ndarray\n",
    "        with proper shape and dtype\n",
    "        :param dct: (dict) json encoded ndarray\n",
    "        :return: (ndarray) if input was an encoded ndarray\n",
    "        \"\"\"\n",
    "        if isinstance(dct, dict) and '__ndarray__' in dct:\n",
    "            data = base64.b64decode(dct['__ndarray__'])\n",
    "            return np.frombuffer(data, dct['dtype']).reshape(dct['shape'])\n",
    "        return dct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testing_ks = range(10,20) + range(20, 55, 5)\n",
    "methods = [\"means\", \"medoids\", \"medians\"]\n",
    "init_types = [\"random\", \"kplusplus\"]\n",
    "\n",
    "# for k in testing_ks:\n",
    "m = methods[0]\n",
    "init_type = init_types[0]\n",
    "k = testing_ks[0]\n",
    "\n",
    "\n",
    "title = m + \"_\" + init_type + \"_cluster\" + str(k)\n",
    "\n",
    "results_set = []\n",
    "with open('./' + title + '/' + title + '_results.json') as data_file:\n",
    "    results_set.append(json.load(data_file,object_hook=json_numpy_obj_hook))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# results_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python main_cluster.py 10 means random 5\n",
      "python main_cluster.py 11 means random 5\n",
      "python main_cluster.py 12 means random 5\n",
      "python main_cluster.py 13 means random 5\n",
      "python main_cluster.py 14 means random 5\n",
      "python main_cluster.py 15 means random 5\n",
      "python main_cluster.py 16 means random 5\n",
      "python main_cluster.py 17 means random 5\n",
      "python main_cluster.py 18 means random 5\n",
      "python main_cluster.py 19 means random 5\n",
      "python main_cluster.py 20 means random 5\n",
      "python main_cluster.py 25 means random 5\n",
      "python main_cluster.py 30 means random 5\n",
      "python main_cluster.py 35 means random 5\n",
      "python main_cluster.py 40 means random 5\n",
      "python main_cluster.py 45 means random 5\n",
      "python main_cluster.py 50 means random 5\n"
     ]
    }
   ],
   "source": [
    "# k = 9\n",
    "for k in testing_ks:\n",
    "    print \"python main_cluster.py {k} {method} {init_type} {prop};\".format(k = k,\n",
    "                                                                        method = m,\n",
    "                                                                        init_type =init_type,\n",
    "                                                                        prop = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
